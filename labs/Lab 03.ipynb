{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Lab Task\n",
    "\n",
    "## More Jupyter Tips\n",
    "\n",
    "Hopefully by this week, you are growing more comfortable with starting Jupyter Notebooks and adding/editing cells. Remember that the keyboard shortcuts are invaluable: running a cell with `Ctrl+Enter`, or adding a new cell below with `B` (in command mode).\n",
    "\n",
    "Two tricks to try this week: autocompletion and retrieving documentation.\n",
    "\n",
    "**Autocomplete**\n",
    "\n",
    "If you start typing a known object or function into Jupyter, you can press `TAB` to finish it. This is especially useful for seeing what functions are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = \"this is a string\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, I've set a string to `test`. If I type `te` then press tab, it will complete the word. This is especially useful for long variable names that you don't want to keep typing. Note that it only completed because there no other options: in that case, there's a scrollable list of candidates for what you might be looking for.\n",
    "\n",
    "The `test` variable is a string. Last week, we saw a two functions that can be performed on strings: `split()` and `join()`. If you would like to see what other options there are for strings, try typing `test.` then press TAB. Magic!\n",
    "\n",
    "![Auto-fill](../images/autofill.png)\n",
    "\n",
    "** Documentation reference **\n",
    "\n",
    "If you want to look up information about a function, you can precede the code running that function with a `?`. For example, if I want to learn how I would use `split()` on `test`, I can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?test.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will open a panel that looks like this in Jupyter:\n",
    "\n",
    "![Info](../images/info.png)\n",
    "\n",
    "The documentation is only as good as what the library is documented, so some libraries might be more or less detailed in this feature.\n",
    "\n",
    "*Questions*\n",
    "\n",
    "- 1) What does `test.isalpha()` do? Copy the documentation string.\n",
    "- 2) Strings have access to a function (whose name starts with a `ce`) that will let you change \"HEADING\" to \"====HEADING====\" (that is, padding with `=` to make the string 15 characters wide). What's the code to do that? (tip: this is an auto-fill question!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to the NLTK\n",
    "\n",
    "This week we'll start using the Natural Language toolkit. For the remaining questions, follow along with:\n",
    "\n",
    "- [Getting NLTK for Text Processing](https://github.com/sgsinclair/alta/blob/2acb6ed09f298f631e4025d33f062f980758a1ce/ipynb/GettingNltk.ipynb), Art of Literary Text Analysis\n",
    "\n",
    "Two notes. First, the tutorial suggests downloading \"all\" packages. However, install the packages from 'book' should be sufficient for now.\n",
    "\n",
    "Also, skip the text processing section, which deals with automatically downloading and cleaning a book. Instead, download this [already-cleaned version of Mary Shelley's Frankenstein](https://raw.githubusercontent.com/organisciak/Text-Mining-Course/master/data/frankenstein.txt), put it into the same folder as your notebook, and load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../data/frankenstein.txt\") as f:\n",
    "    frankensteinString = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a quick way of viewing part of our string: the first 250 characters. Notice that you can select subsets of strings like you select subsets of lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ï»¿Letter 1\\n\\nSt. Petersburgh, Dec. 11th, 17--\\n\\nTO Mrs. Saville, England\\n\\nYou will rejoice to hear that no disaster has accompanied the\\ncommencement of an enterprise which you have regarded with such evil\\nforebodings.  I arrived here yesterday, and my'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frankensteinString[0:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > Side-note for the Python novice: you don't actually need the zero in [0:250]. If left blank, like '[:250]`, Python will assume \"from the very start\", which is the same as using a 0. If you leave the second part blank, Python will assume \"until the very end\".\n",
    "    \n",
    "For the rest of the ALTA chapter, follow along using `frankensteinString` string instead of `goldBugString`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Questions__\n",
    "\n",
    " - 3) Use the `word_tokenize` function on Frankenstein, as shown in ALTA. What are tokens 39:67? Hint: this is a full sentence. Include your code.\n",
    " - 4) Create a sample of only the tokens where the first character is an alphabetical character. In this sample, what are tokens 1215:1221? Again, this will be a sentence, but won't include punctuation as tokens. Include your code.\n",
    " \n",
    " _For the next questions use the list of tokens that start with an alphabetical character._\n",
    " \n",
    " \n",
    " - 5) What are the ten most frequent words in this book? Create a frequency distribution of the words from question 4, then tabulate the top 10 words. Include your code.\n",
    " - 6) After case-folding, what are the ten most frequent words in this book? Include your code.\n",
    " - 7) Rewrite this list comprehension as a `for` loop (what ALTA called technique 1): `[word for word in listOfWords if word.find('-') >= 0]`. No output necessary, just the code, but feel free to test it out.\n",
    " - 8) We're going to use a customized stoplist. First, load the NLTK stoplist, and add the words 'could', 'would', 'upon', and 'yet' to the stoplist. What are the top ten case-folded words when stopping against the stoplist. Include your code and paste the tabulated output.\n",
    " \n",
    "Using the autocomplete in Jupyter, you may notice that a list of tokens converted to a `FreqDist` object has more methods than just `tabulate()`. One really cool one is `plot()`.\n",
    "\n",
    "`plot` gives you a visualization of the top frequency words. However, you may notice that if you try to run it, the visualization doesn't show up.\n",
    "\n",
    "It _is_ created, but Jupyter just doesn't know that you want the visualization shown _within_ the notebook. To turn that option on, run the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only necessary once: it tells Jupyter to show plots 'inline' (ie. inside the notebook).\n",
    "\n",
    "**Questions**\n",
    "\n",
    "- 9) Write the code to plot the top forty stoplisted, lowercase words (from question 8). And again, remember the docs! The output will look similar to this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](../images/freqplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 10) Enter the first 5 concordances for the word \"monster\" in the original token list - the list straight from word_tokenize that included punctuation and numbers - narrowing the search to a 49-characters window. Include the code. Tip: See the docs for the concordance tool in Jupyter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
