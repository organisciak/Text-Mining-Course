{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07 Companion\n",
    "\n",
    "This notebook describes how the HTRC Extracted Features files were converted to 'wide' dataframes of book x word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from htrc_features import FeatureReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas: combining multiple EF files into one token list\n",
    "\n",
    "I've added a set of English and French books to our course content: https://github.com/organisciak/Text-Mining-Course/tree/master/data/classification. Here are the paths (as they look on my system):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/classification/train\\\\hvd.32044014292023.json.bz2',\n",
       " '../data/classification/train\\\\hvd.32044102860673.json.bz2',\n",
       " '../data/classification/train\\\\mdp.39015038910694.json.bz2',\n",
       " '../data/classification/train\\\\pst.000029579440.json.bz2',\n",
       " '../data/classification/train\\\\uiug.30112037882914.json.bz2',\n",
       " '../data/classification/train\\\\wu.89104415476.json.bz2',\n",
       " '../data/classification/test\\\\mdp.39015004295880.json.bz2',\n",
       " '../data/classification/test\\\\mdp.39015005725919.json.bz2',\n",
       " '../data/classification/test\\\\mdp.39015008815865.json.bz2',\n",
       " '../data/classification/test\\\\mdp.39015066049530.json.bz2',\n",
       " '../data/classification/test\\\\mdp.39076002736721.json.bz2',\n",
       " '../data/classification/test\\\\pst.000062491532.json.bz2']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Glob lets us select a number of files using a 'wildcard'\n",
    "import glob\n",
    "train_paths = glob.glob('../data/classification/train/*bz2')\n",
    "test_paths = glob.glob('../data/classification/test/*bz2')\n",
    "(train_paths + test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the files can be loaded into the FeatureReader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr = FeatureReader(train_paths + test_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we work with *all of them*, consider the type of information we want for each book. We want a DataFrame for each book with with word counts, put together into a list.\n",
    "\n",
    "1) Get a tokenlist DataFrame for the volume, ignoring case, parts of speech, and pages. For simplicity, convert the index to columns, and drop the column called 'section'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowercase</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!'</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lowercase  count\n",
       "0         !    868\n",
       "1        !'      1\n",
       "2       !33      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = fr.first()\n",
    "tl = (vol.tokenlist(pages=False, pos=False, case=False)\n",
    "         .reset_index()\n",
    "         .drop('section', 1)\n",
    "      )\n",
    "tl.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dropping the section column with `drop('section', 1)`, the `1` refers to the axis, so Pandas knows that you're refering to a column and not a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) We want to stick the tokenlists together, so add information that we don't want to lose - the book identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowercase</th>\n",
       "      <th>count</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>868</td>\n",
       "      <td>hvd.32044014292023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!'</td>\n",
       "      <td>1</td>\n",
       "      <td>hvd.32044014292023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!33</td>\n",
       "      <td>1</td>\n",
       "      <td>hvd.32044014292023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lowercase  count                book\n",
       "0         !    868  hvd.32044014292023\n",
       "1        !'      1  hvd.32044014292023\n",
       "2       !33      1  hvd.32044014292023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl['book'] = vol.id\n",
    "tl.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it together: here is a function that takes a volume and returns the desired dataframe as the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataframe(input_volume, pos=False, pages=False):\n",
    "    tl = (input_volume.tokenlist(pages=pages, pos=pos, case=False)\n",
    "                      .reset_index()\n",
    "                      .drop('section', 1)\n",
    "      )\n",
    "    tl['book'] = input_volume.id\n",
    "\n",
    "    return tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowercase</th>\n",
       "      <th>count</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!</td>\n",
       "      <td>868</td>\n",
       "      <td>hvd.32044014292023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!'</td>\n",
       "      <td>1</td>\n",
       "      <td>hvd.32044014292023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!33</td>\n",
       "      <td>1</td>\n",
       "      <td>hvd.32044014292023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lowercase  count                book\n",
       "0         !    868  hvd.32044014292023\n",
       "1        !'      1  hvd.32044014292023\n",
       "2       !33      1  hvd.32044014292023"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_dataframe(vol).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So, lets use a loop to collect this for every single volume in fr.volumes(), then use `pd.concat` to join everything.\n",
    "\n",
    "At the same time, save a list with additional book information: the title and the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lowercase</th>\n",
       "      <th>count</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6917</th>\n",
       "      <td>jaunes</td>\n",
       "      <td>3</td>\n",
       "      <td>mdp.39015008815865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>a-drinking</td>\n",
       "      <td>1</td>\n",
       "      <td>pst.000029579440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>earshot</td>\n",
       "      <td>1</td>\n",
       "      <td>mdp.39076002736721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>piquant</td>\n",
       "      <td>1</td>\n",
       "      <td>mdp.39015008815865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10360</th>\n",
       "      <td>recoiled</td>\n",
       "      <td>5</td>\n",
       "      <td>mdp.39076002736721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lowercase  count                book\n",
       "6917       jaunes      3  mdp.39015008815865\n",
       "475    a-drinking      1    pst.000029579440\n",
       "4362      earshot      1  mdp.39076002736721\n",
       "9704      piquant      1  mdp.39015008815865\n",
       "10360    recoiled      5  mdp.39076002736721"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_dataframes = []\n",
    "book_information = []\n",
    "\n",
    "for vol in fr.volumes():\n",
    "    df = prepare_dataframe(vol)\n",
    "    book_dataframes.append(df)\n",
    "    book_information.append((vol.id, vol.title, vol.language))\n",
    "    \n",
    "books = pd.concat(book_dataframes)\n",
    "language_assignments = pd.DataFrame(book_information, columns=['book', 'title', 'language'])\n",
    "\n",
    "books.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of junk words or uninteresting words, so filter to words that show up at least $n$ times across the entire collection.\n",
    "\n",
    "Don't stoplist, because that we're looking across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_filtered = books.groupby('lowercase').filter(lambda x: x['count'].sum() > 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`books` is 'long', meaning each word is in it's own row. To make it wide we need to pivot the DataFrame. The hope is for a DataFrame where each row is a book, each column is a word, and the cells are the frequency counts. Consider how that request becomes the arguments for `books.pivot()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>lowercase</th>\n",
       "      <th>!</th>\n",
       "      <th>!—</th>\n",
       "      <th>!—the</th>\n",
       "      <th>\"</th>\n",
       "      <th>\"\"</th>\n",
       "      <th>\"because</th>\n",
       "      <th>\"if</th>\n",
       "      <th>\"it</th>\n",
       "      <th>\"only</th>\n",
       "      <th>\"or</th>\n",
       "      <th>...</th>\n",
       "      <th>ﬂight</th>\n",
       "      <th>ﬂights</th>\n",
       "      <th>ﬂoor</th>\n",
       "      <th>ﬂown</th>\n",
       "      <th>ﬂuid</th>\n",
       "      <th>ﬂung</th>\n",
       "      <th>ﬂush</th>\n",
       "      <th>ﬂushed</th>\n",
       "      <th>ﬂy</th>\n",
       "      <th>ﬂying</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hvd.32044014292023</th>\n",
       "      <td>868.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4582.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hvd.32044102860673</th>\n",
       "      <td>1354.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015038910694</th>\n",
       "      <td>910.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pst.000029579440</th>\n",
       "      <td>452.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2835.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uiug.30112037882914</th>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wu.89104415476</th>\n",
       "      <td>573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015004295880</th>\n",
       "      <td>565.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015005725919</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015008815865</th>\n",
       "      <td>963.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39015066049530</th>\n",
       "      <td>119.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdp.39076002736721</th>\n",
       "      <td>508.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pst.000062491532</th>\n",
       "      <td>3765.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>596.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 16115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lowercase                 !   !—  !—the       \"    \"\"  \"because   \"if   \"it  \\\n",
       "book                                                                          \n",
       "hvd.32044014292023    868.0  0.0    0.0  4582.0   2.0       6.0  10.0  22.0   \n",
       "hvd.32044102860673   1354.0  0.0    0.0   139.0   0.0       0.0   0.0   0.0   \n",
       "mdp.39015038910694    910.0  5.0    9.0    29.0   0.0       0.0   0.0   0.0   \n",
       "pst.000029579440      452.0  3.0    1.0  2835.0  71.0       2.0   4.0   5.0   \n",
       "uiug.30112037882914   159.0  0.0    0.0     2.0   0.0       0.0   0.0   0.0   \n",
       "wu.89104415476        573.0  0.0    0.0    12.0   0.0       0.0   0.0   0.0   \n",
       "mdp.39015004295880    565.0  0.0    0.0    13.0   0.0       0.0   0.0   0.0   \n",
       "mdp.39015005725919    314.0  0.0    0.0    21.0   0.0       0.0   0.0   0.0   \n",
       "mdp.39015008815865    963.0  0.0    0.0    33.0   0.0       0.0   0.0   0.0   \n",
       "mdp.39015066049530    119.0  0.0    0.0    51.0   0.0       0.0   0.0   0.0   \n",
       "mdp.39076002736721    508.0  0.0    1.0    11.0   0.0       0.0   0.0   0.0   \n",
       "pst.000062491532     3765.0  0.0    0.0   596.0   0.0       0.0   2.0   0.0   \n",
       "\n",
       "lowercase            \"only  \"or  ...    ﬂight  ﬂights  ﬂoor  ﬂown  ﬂuid  ﬂung  \\\n",
       "book                             ...                                            \n",
       "hvd.32044014292023     7.0  6.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "hvd.32044102860673     0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "mdp.39015038910694     0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "pst.000029579440       2.0  1.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "uiug.30112037882914    0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "wu.89104415476         0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "mdp.39015004295880     0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "mdp.39015005725919     0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "mdp.39015008815865     0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "mdp.39015066049530     0.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "mdp.39076002736721     0.0  0.0  ...     45.0     6.0  74.0  23.0   6.0   9.0   \n",
       "pst.000062491532       1.0  0.0  ...      0.0     0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "lowercase            ﬂush  ﬂushed     ﬂy  ﬂying  \n",
       "book                                             \n",
       "hvd.32044014292023    0.0     0.0    0.0    0.0  \n",
       "hvd.32044102860673    0.0     0.0    0.0    0.0  \n",
       "mdp.39015038910694    0.0     0.0    0.0    0.0  \n",
       "pst.000029579440      0.0     0.0    0.0    0.0  \n",
       "uiug.30112037882914   0.0     0.0    0.0    0.0  \n",
       "wu.89104415476        0.0     0.0    0.0    0.0  \n",
       "mdp.39015004295880    0.0     0.0    0.0    0.0  \n",
       "mdp.39015005725919    0.0     0.0    0.0    0.0  \n",
       "mdp.39015008815865    0.0     0.0    0.0    0.0  \n",
       "mdp.39015066049530    0.0     0.0    0.0    0.0  \n",
       "mdp.39076002736721    6.0     9.0  131.0   52.0  \n",
       "pst.000062491532      0.0     0.0    0.0    0.0  \n",
       "\n",
       "[12 rows x 16115 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_order = language_assignments['book']\n",
    "wide_books = (books_filtered.pivot(index='book', columns='lowercase', values='count')\n",
    "                            .fillna(0)\n",
    "                            .loc[book_order]\n",
    "              )\n",
    "wide_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the pivot:\n",
    " - I added 'fillna(0)': this put in a `0` for every missing (`n/a`) value.\n",
    " - I took the book names from the information dataframe, and ordered the `wide_books` rows in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wide_books.to_csv('../data/classification/english_french_class.csv', encoding='utf-8')\n",
    "language_assignments.to_csv('../data/classification/english_french_class_labels.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Molding a new document to have the same column order of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>lowercase</th>\n",
       "      <th>!</th>\n",
       "      <th>!—nay</th>\n",
       "      <th>!—that</th>\n",
       "      <th>!—you</th>\n",
       "      <th>\"</th>\n",
       "      <th>\"and</th>\n",
       "      <th>\"are</th>\n",
       "      <th>\"because</th>\n",
       "      <th>\"dear</th>\n",
       "      <th>\"do</th>\n",
       "      <th>...</th>\n",
       "      <th>—my</th>\n",
       "      <th>—one</th>\n",
       "      <th>—save</th>\n",
       "      <th>—she</th>\n",
       "      <th>—the</th>\n",
       "      <th>—their</th>\n",
       "      <th>—to</th>\n",
       "      <th>•</th>\n",
       "      <th>•93</th>\n",
       "      <th>•dons</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hvd.hn6ltf</th>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>723</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lowercase     !  !—nay  !—that  !—you    \"  \"and  \"are  \"because  \"dear  \"do  \\\n",
       "book                                                                           \n",
       "hvd.hn6ltf  166      1       1      1  723     1     1         1      1    1   \n",
       "\n",
       "lowercase   ...    —my  —one  —save  —she  —the  —their  —to  •  •93  •dons  \n",
       "book        ...                                                              \n",
       "hvd.hn6ltf  ...      2     1      1     1     1       1    2  2    1      1  \n",
       "\n",
       "[1 rows x 7783 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = FeatureReader('../data/hvd.hn6ltf.json.bz2').first()\n",
    "tl = prepare_dataframe(vol)\n",
    "tl_wide = tl.pivot(index='book', columns='lowercase', values='count').fillna(0)\n",
    "tl_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the new document has different words than the training data. To get the appropriate column order, first save the wide_books columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = wide_books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is a bit ugly. If you concat the new book with a zero row version of the training data (`wide_books.head(0)`), it will add missing values for all the words that the new book doesn't have. Then, you can select just the relevant columns (the `[c]` part), and fill the missing values with zero again (`fillna(0)`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>!—</th>\n",
       "      <th>!—the</th>\n",
       "      <th>\"</th>\n",
       "      <th>\"\"</th>\n",
       "      <th>\"because</th>\n",
       "      <th>\"if</th>\n",
       "      <th>\"it</th>\n",
       "      <th>\"only</th>\n",
       "      <th>\"or</th>\n",
       "      <th>...</th>\n",
       "      <th>ﬂight</th>\n",
       "      <th>ﬂights</th>\n",
       "      <th>ﬂoor</th>\n",
       "      <th>ﬂown</th>\n",
       "      <th>ﬂuid</th>\n",
       "      <th>ﬂung</th>\n",
       "      <th>ﬂush</th>\n",
       "      <th>ﬂushed</th>\n",
       "      <th>ﬂy</th>\n",
       "      <th>ﬂying</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hvd.hn6ltf</th>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 16115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                !   !—  !—the      \"   \"\"  \"because  \"if  \"it  \"only  \"or  \\\n",
       "book                                                                        \n",
       "hvd.hn6ltf  166.0  0.0    0.0  723.0  0.0       1.0  1.0  2.0    0.0  1.0   \n",
       "\n",
       "            ...    ﬂight  ﬂights  ﬂoor  ﬂown  ﬂuid  ﬂung  ﬂush  ﬂushed   ﬂy  \\\n",
       "book        ...                                                               \n",
       "hvd.hn6ltf  ...      0.0     0.0   0.0   0.0   0.0   0.0   0.0     0.0  0.0   \n",
       "\n",
       "            ﬂying  \n",
       "book               \n",
       "hvd.hn6ltf    0.0  \n",
       "\n",
       "[1 rows x 16115 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_book = pd.concat([tl_wide, wide_books.head(0)])[c].fillna(0)\n",
    "new_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing contemporary author example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paths = glob.glob('../data/contemporary_books/dataset_files/*bz2')\n",
    "fr = FeatureReader(paths)\n",
    "\n",
    "book_dataframes = []\n",
    "book_information = []\n",
    "\n",
    "for vol in fr.volumes():\n",
    "    df = prepare_dataframe(vol, pos=True)\n",
    "    book_dataframes.append(df)\n",
    "    # Author is a list, like \"[King, Stephen 1947- ]\", so we'll grab just the first item,\n",
    "    # and truncate at the first comma\n",
    "    author = vol.author[0].split(',')[0]\n",
    "    # Title includes the author name, as in \"Carrie / Stephen King.\", so truncate \n",
    "    title = vol.title.split(' / ')[0]\n",
    "    book_information.append((vol.id, author, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books = pd.concat(book_dataframes)\n",
    "\n",
    "# Include only nouns (non-proper), verbs, adverbs, adjectives, and interjections\n",
    "include_pos = ['NN', 'NNS', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',\n",
    "               'RB', 'RBR', 'RBS','JJ', 'JJS', 'JJR','UH']\n",
    "good_pos = books['pos'].isin(include_pos)\n",
    "stopword = books['lowercase'].isin(stopwords.words('english'))\n",
    "alpha = books['lowercase'].str.isalpha()\n",
    "\n",
    "books_filtered = (books[~stopword & alpha & good_pos]\n",
    "                    .groupby('lowercase')\n",
    "                    .filter(lambda x: x['count'].sum() > 5)\n",
    "                 )\n",
    "\n",
    "info = pd.DataFrame(book_information, columns=['book', 'author', 'title'])\n",
    "book_order = info['book']\n",
    "wide_books = (books_filtered.groupby(['book', 'lowercase'], as_index=False)[['count']].sum()\n",
    "                            .pivot(index='book', columns='lowercase', values='count')\n",
    "                            .fillna(0)\n",
    "                            .loc[book_order]\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mdp.39015046381565</td>\n",
       "      <td>Grisham</td>\n",
       "      <td>A time to kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mdp.39015005028686</td>\n",
       "      <td>King</td>\n",
       "      <td>The stand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>uc1.32106012198112</td>\n",
       "      <td>King</td>\n",
       "      <td>Stephen King's Danse macabre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdp.39015031703609</td>\n",
       "      <td>Grisham</td>\n",
       "      <td>The rainmaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mdp.39015038148048</td>\n",
       "      <td>King</td>\n",
       "      <td>Desperation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  book   author                         title\n",
       "9   mdp.39015046381565  Grisham                A time to kill\n",
       "0   mdp.39015005028686     King                     The stand\n",
       "29  uc1.32106012198112     King  Stephen King's Danse macabre\n",
       "4   mdp.39015031703609  Grisham                 The rainmaker\n",
       "5   mdp.39015038148048     King                   Desperation"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wide_books.to_csv('../data/contemporary_books/contemporary.csv', encoding='utf-8')\n",
    "info.to_csv('../data/contemporary_books/contemporary_labels.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page-level\n",
    "\n",
    "Just to make the dataset a little bit smaller, this example actually uses 10 pages at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paths = glob.glob('../data/contemporary_books/dataset_files/*bz2')\n",
    "fr = FeatureReader(paths)\n",
    "\n",
    "book_dataframes = []\n",
    "book_information = []\n",
    "\n",
    "for vol in fr.volumes():\n",
    "    df = prepare_dataframe(vol, pages=True, pos=True)\n",
    "    book_dataframes.append(df)\n",
    "    author = vol.author[0].split(',')[0]\n",
    "    title = vol.title.split(' / ')[0]\n",
    "    book_information.append((vol.id, author, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books = pd.concat(book_dataframes)\n",
    "books['pageblock'] = books['page'].apply(lambda x: 0 + x - x % 10)\n",
    "books['id'] = books['book'] + '-' + books['pageblock'].astype(str)\n",
    "\n",
    "# Filter by POS: keep only nouns (non-proper)\n",
    "include_pos = ['NN', 'NNS']\n",
    "good_pos = books['pos'].isin(include_pos)\n",
    "stopword = books['lowercase'].isin(stopwords.words('english'))\n",
    "alpha = books['lowercase'].str.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books_filtered = (books[~stopword & alpha & good_pos]\n",
    "                    .groupby('lowercase')\n",
    "                    .filter(lambda x: x['count'].sum() > 5)\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = pd.DataFrame(book_information, columns=['book', 'author', 'title'])\n",
    "info_with_pages = pd.merge(info, books_filtered[['book', 'pageblock']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>pageblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mdp.39015005028686</td>\n",
       "      <td>King</td>\n",
       "      <td>The stand</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdp.39015005028686</td>\n",
       "      <td>King</td>\n",
       "      <td>The stand</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdp.39015005028686</td>\n",
       "      <td>King</td>\n",
       "      <td>The stand</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdp.39015005028686</td>\n",
       "      <td>King</td>\n",
       "      <td>The stand</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdp.39015005028686</td>\n",
       "      <td>King</td>\n",
       "      <td>The stand</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 book author      title  pageblock\n",
       "0  mdp.39015005028686   King  The stand          0\n",
       "1  mdp.39015005028686   King  The stand         10\n",
       "2  mdp.39015005028686   King  The stand         20\n",
       "3  mdp.39015005028686   King  The stand         30\n",
       "4  mdp.39015005028686   King  The stand         40"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_with_pages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page_order = (info_with_pages['book'] + '-' + info_with_pages['pageblock'].astype(str))\n",
    "wide_books = (books_filtered.groupby(['id', 'lowercase'], as_index=False)[['count']].sum()\n",
    "                            .pivot(index='id', columns='lowercase', values='count')\n",
    "                            .fillna(0)\n",
    "                            .loc[page_order]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note the compression\n",
    "wide_books.to_csv('../data/contemporary_books/contemporary-pages.csv.gz', encoding='utf-8', compression='gzip')\n",
    "info_with_pages.to_csv('../data/contemporary_books/contemporary-pages_labels.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
